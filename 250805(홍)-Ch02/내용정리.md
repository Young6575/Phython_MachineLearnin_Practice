
# 모델의 복잡도와 일반화 사이의 관계
- 이웃의 숫자가 적을 때: 모델이 복잡 > 훈련 정확도 높다 > 테스트 정확도 낮다
- 이웃의 숫자가 많을 때:  모델이 단순해짐 > 훈련 정확도 떨어진다 

# 결정계수
구글링: 결정 계수의 의미와 계산 방법, 여울, 20.8.9, https://m.blog.naver.com/tlrror9496/222055889079

결정계수(R^2)의 이해, 노마프분석가, 22.3.8, https://diseny.tistory.com/entry/%EA%B2%B0%EC%A0%95%EA%B3%84%EC%88%98R2%EC%9D%98-%EC%9D%B4%ED%95%B4?category=906035

- 결정계수: R 제곱 R square = SSE/SST = 1 - SSR/SST (1- 설명 안되는 분산/총분산)
- 1이면 독립변수가 종속변수를 잘 설명한다 





# 선형모델
[딥러닝] 선형회귀 Linear Regression - 최소제곱법, 평균제곱오차, 경사하강법, 멍개, 21.2.20, https://m.blog.naver.com/pjt3591oo/222250225034


## 백터 내적
벡터 내적:product > 모델의 예측, 손실 계산, 신경망의 출력 등 거의 모든 연산의 기반
- 벡터 내적이란? 각 원소끼리 곱하고 모두 더한 것 → 결과는 스칼라(숫자 하나)

  a = (a1,a2), b = (b1,b2)
  a.b = a1b1 + a2b2

  머신러닝에서 X=(1,3), w=(3,)일 때 >3은 특성 갯수 
 -   y = w0 * x0 + w1 * x1 + w2 *x2 +b 회귀식
w(가중치)


## 최소제곱법
- y = wx + b # 학습으로 w,b를 찾는다 


## 경사하강법
[딥러닝] 선형회귀 Linear Regression - 최소제곱법, 평균제곱오차, 경사하강법, 멍개, 21.2.20, https://m.blog.naver.com/pjt3591oo/222250225034


## 리지 회귀
ridge:  산마루, 산등성이 - elevated body part or structure
- 해석: 복잡한 골짜기를 숨긴다
- ridge는 최적화 함수의 형태에서 유래한 용어


### 정규화
[정규화(regulation)와 Ridge Regression,yuns_u·2021년 8월 11일, ](https://velog.io/@yuns_u/Ridge-Regression)
- regulate: to control something, by making it work in a particular way
- 규제: 과대적합이 되지 않도록 모델을 강제로 제한 >wi을 0에 가깝게 만든다 >> L2 규제
